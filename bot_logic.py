import json
import random
import re
from datetime import datetime
from pathlib import Path
from collections import deque

from modules.tictactoe import TicTacToe
from nlp_utils import clean_text, lemmatize_text, correct_spelling
from intent_classifier import IntentClassifier
from sentiment import get_sentiment
from recommendations import recommend
from dialogue_retrieval import DialogueRetriever


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ —Ñ–∞–π–ª—ã –∏ –º–æ–¥–µ–ª–∏ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
BASE_DIR = Path(__file__).parent
DATA_DIR = BASE_DIR / "data"
INTENTS_F = DATA_DIR / "intents_dataset.json"
CUSTOM_F = DATA_DIR / "custom_intents.json"
CATALOG_F = DATA_DIR / "product_catalog.json"
DIALOG_F = DATA_DIR / "dialogues.txt"

INTENTS = json.loads(INTENTS_F.read_text("utf-8"))
if CUSTOM_F.exists():
    INTENTS.update(json.loads(CUSTOM_F.read_text("utf-8")))

PRODUCT_CATALOG = json.loads(CATALOG_F.read_text("utf-8"))

# –∑–∞–≥—Ä—É–∂–∞–µ–º –æ–±—É—á–µ–Ω–Ω—ã–µ *.pkl
clf = IntentClassifier(DATA_DIR)
clf.load()
retriever = DialogueRetriever(str(DIALOG_F))

# —Å–ª–æ–≤–∞—Ä—å –¥–ª—è spell-checker
DICTIONARY = {
    ex.lower()
    for d in INTENTS.values()
    if isinstance(d, dict)
    for ex in d.get("examples", [])
}
if DIALOG_F.exists():
    for ln in DIALOG_F.read_text("utf-8").splitlines():
        DICTIONARY.update(map(str.lower, re.findall(r"[–ê-–Ø–∞-—èA-Za-z—ë]+", ln)))

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ —Ä–µ–∫–ª–∞–º–∞ / –æ—Ñ—Ñ–µ—Ä—ã ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
AD_COOLDOWN_MSG = 3
AD_COOLDOWN_HOURS = 1

SEASONAL_EVENTS = {
    "11-11": "–ß—ë—Ä–Ω–∞—è –ø—è—Ç–Ω–∏—Ü–∞",
    "03-08": "8 –º–∞—Ä—Ç–∞",
    "23-02": "23 —Ñ–µ–≤—Ä–∞–ª—è",
}

AD_TRIGGERS = {
    ("—Å–æ–Ω", "—É—Å—Ç–∞–ª", "—Å–ø–∞–ª"): (
        "–ú–∞—Ç—Ä–∞—Å—ã",
        None,
        "–ö—Å—Ç–∞—Ç–∏, —Ö–æ—Ä–æ—à–∏–π –º–∞—Ç—Ä–∞—Å —Ç–≤–æ—Ä–∏—Ç —á—É–¥–µ—Å–∞ —Å–æ —Å–Ω–æ–º. –•–æ—á–µ—à—å –≤–∑–≥–ª—è–Ω—É—Ç—å?",
    ),
    ("—Å–ø–∏–Ω–∞", "–±–æ–ª–∏—Ç", "–ø–æ—è—Å–Ω–∏—Ü–∞"): (
        "–ú–∞—Ç—Ä–∞—Å—ã",
        "–æ—Ä—Ç–æ–ø–µ–¥–∏—á–µ—Å–∫–∏–µ",
        "–ü–æ–º–æ–∂–µ—Ç –æ—Ä—Ç–æ–ø–µ–¥–∏—á–µ—Å–∫–∏–π –º–∞—Ç—Ä–∞—Å —Å –∑–æ–Ω–∞–ª—å–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π üòâ",
    ),
    ("–ø–µ—Ä–µ–µ–∑–¥", "—Ä–µ–º–æ–Ω—Ç", "–∫–≤–∞—Ä—Ç–∏—Ä"): (
        "–ö—Ä–æ–≤–∞—Ç–∏",
        None,
        "–ù–æ–≤–æ—Å–µ–ª—å–µ ‚Äî –æ—Ç–ª–∏—á–Ω—ã–π –ø–æ–≤–æ–¥ –æ–±–Ω–æ–≤–∏—Ç—å –∫—Ä–æ–≤–∞—Ç—å. –ü–æ–¥–∫–∏–Ω—É—Ç—å –∏–¥–µ–∏?",
    ),
}


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ helpers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def _save_custom_intents(data: dict) -> None:
    DATA_DIR.mkdir(exist_ok=True)
    CUSTOM_F.write_text(json.dumps(data, ensure_ascii=False, indent=4), "utf-8")


def _parse_iso(ts):
    if ts is None or isinstance(ts, datetime):
        return ts
    try:
        return datetime.fromisoformat(ts)
    except ValueError:
        return None


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ core ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def get_response(text: str, user_data: dict, history: deque) -> str:
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è-–æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–∏–∞–ª–æ–≥–∞."""
    prefs = user_data.setdefault("preferences", {})
    custom_ans = user_data.setdefault("custom_answers", {})
    last_int = user_data.get("last_intent")
    last_bot = user_data.get("last_bot")

    low = text.strip().lower()
    low_clean = re.sub(r"[^–∞-—è—ëa-z0-9\s]", "", low)

    # --- –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º —Ç–∏–ø—ã --------------------------------
    user_data["asked_questions"] = set(user_data.get("asked_questions", []))
    user_data["shown_products"] = set(user_data.get("shown_products", []))
    user_data.setdefault("asked_followup", False)
    user_data.setdefault("msgs_since_ad", 0)
    user_data["last_ad_ts"] = _parse_iso(user_data.get("last_ad_ts"))

    # —Å—á—ë—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
    user_data["msgs_since_ad"] += 1
    now = datetime.utcnow()
    last_ad_dt = user_data["last_ad_ts"]
    hours_since = ((now - last_ad_dt).total_seconds() / 3600) if last_ad_dt else 1e9

    def _can_offer() -> bool:
        return user_data["msgs_since_ad"] >= AD_COOLDOWN_MSG and hours_since >= AD_COOLDOWN_HOURS

    def _offer(resp: str) -> str:
        user_data.update(last_ad_ts=now.isoformat(), msgs_since_ad=0)
        return resp

    # ------------------------------------------------------
    # small-talk
    if re.search(r"\b–∫–∞–∫\s+(–¥–µ–ª[–∞–∏]|—Ç—ã)\b", low_clean):
        return random.choice(
            [
                "–£ –º–µ–Ω—è –≤—Å—ë –æ—Ç–ª–∏—á–Ω–æ, —Å–ø–∞—Å–∏–±–æ! –ê —É —Ç–µ–±—è –∫–∞–∫?",
                "–í—Å—ë —Ö–æ—Ä–æ—à–æ, —Ä–∞–±–æ—Ç–∞—é –Ω–µ –ø–æ–∫–ª–∞–¥–∞—è —Ç—Ä–∞–Ω–∑–∏—Å—Ç–æ—Ä–æ–≤ üòÑ –ê —Ç—ã?",
            ]
        )
    if "–Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏" in low_clean:
        return random.choice(
            [
                "–ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å—É–ø–µ—Ä! –ö–∞–∫ —Ç–≤–æ—ë?",
                "–ë–æ–¥—Ä–æ–µ –∏ –≤–µ—Å—ë–ª–æ–µ. –£ —Ç–µ–±—è –∫–∞–∫–æ–µ?",
            ]
        )

    # –æ–∂–∏–¥–∞–µ–º—ã–π –∂–∞–Ω—Ä
    if user_data.get("awaiting_genre"):
        cat = user_data.pop("awaiting_genre")
        reply = recommend(cat, low_clean)
        prefs[f"{cat}_genre"] = low_clean
        user_data.update(last_intent=cat, last_bot=reply)
        return reply

    # —Å–µ–∑–æ–Ω–Ω—ã–µ –æ—Ñ—Ñ–µ—Ä—ã
    mmdd = now.strftime("%m-%d")
    if mmdd in SEASONAL_EVENTS and _can_offer():
        return _offer(
            f"–î–æ {SEASONAL_EVENTS[mmdd]} —Å–∫–∏–¥–∫–∞ ‚àí25 % –Ω–∞ –º–∞—Ç—Ä–∞—Å—ã. –ü–æ–∫–∞–∑–∞—Ç—å –≤–∞—Ä–∏–∞–Ω—Ç—ã?"
        )

    # —Ç—Ä–∏–≥–≥–µ—Ä–Ω—ã–µ –æ—Ñ—Ñ–µ—Ä—ã
    for keys, (cat, sub, pitch) in AD_TRIGGERS.items():
        if any(k in low_clean for k in keys) and _can_offer():
            user_data.update(
                expecting_more_ads=True,
                last_ad_category=cat,
                last_ad_subcategory=sub,
                ad_offer_shown=True,
            )
            if sub:  # —Å—Ä–∞–∑—É –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–≤–∞—Ä
                prod = random.choice(PRODUCT_CATALOG[cat][sub])
                return _offer(
                    pitch
                    + f"\n\n*{prod['name']}*\n{prod['description']}\n"
                    f"–¶–µ–Ω–∞: {prod['price']} ‚ÇΩ\n–ü–æ–¥—Ä–æ–±–Ω–µ–µ: {prod['link']}"
                )
            user_data["awaiting_ad_choice"] = True
            return _offer(pitch)

    # —Å–±—Ä–æ—Å —Ä–µ–∂–∏–º–∞ ¬´–µ—â—ë¬ª
    if user_data.get("expecting_more_ads") and low not in {"–µ—â–µ", "–µ—â—ë", "–µ—â–µ —Ä–∞–∑", "–µ—â—ë —Ä–∞–∑"}:
        user_data["expecting_more_ads"] = False
        user_data["shown_products"].clear()

    # –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–∑–≤–∞–ª –∫–∞—Ç–µ–≥–æ—Ä–∏—é –Ω–∞–ø—Ä—è–º—É—é
    for cat in PRODUCT_CATALOG:
        if re.search(rf"\b{cat.lower()}\b", low_clean):
            user_data.pop("awaiting_ad_choice", None)
            user_data.update(shopping_category=cat, ad_offer_shown=True, ad_offer_done=False)
            subs = ", ".join(PRODUCT_CATALOG[cat])
            return f"–û—Ç–ª–∏—á–Ω–æ! –ö–∞–∫–∏–µ –∏–º–µ–Ω–Ω–æ {cat.lower()} –∏–Ω—Ç–µ—Ä–µ—Å—É—é—Ç: {subs}?"

    # —è–≤–Ω—ã–π /catalog
    def _catalog_offer() -> str:
        user_data["awaiting_ad_choice"] = True
        return (
            "–ö—Å—Ç–∞—Ç–∏, —É –Ω–∞—Å –≤ –∫–∞—Ç–∞–ª–æ–≥–µ –µ—Å—Ç—å –æ—Ç–ª–∏—á–Ω—ã–µ **–∫—Ä–æ–≤–∞—Ç–∏** –∏ **–º–∞—Ç—Ä–∞—Å—ã**.\n"
            "–ß—Ç–æ —Ç–µ–±–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–µ–µ: –∫—Ä–æ–≤–∞—Ç–∏ –∏–ª–∏ –º–∞—Ç—Ä–∞—Å—ã?"
        )

    if any(cmd in low for cmd in ("/catalog", "–∫–∞—Ç–∞–ª–æ–≥", "—Ç–æ–≤–∞—Ä—ã")) and _can_offer():
        user_data["ad_offer_shown"] = True
        return _offer(_catalog_offer())

    # –∞–≤—Ç–æ-–æ—Ñ—Ñ–µ—Ä –ø–æ—Å–ª–µ 3 —Ä–µ–ø–ª–∏–∫
    if (
        len(history) >= 3
        and not user_data.get("ad_offer_shown")
        and not user_data.get("awaiting_ad_choice")
        and _can_offer()
    ):
        user_data["ad_offer_shown"] = True
        return _offer(_catalog_offer())

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –≤—ã–±–æ—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    if user_data.get("awaiting_ad_choice"):
        if low_clean in {"–Ω–µ—Ç", "–Ω–µ", "–Ω–µ–∞", "no"}:
            user_data.pop("awaiting_ad_choice")
            user_data["ad_offer_shown"] = True
            return "–û–∫–µ–π! –ï—Å–ª–∏ –∑–∞—Ö–æ—á–µ—à—å –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∫–∞—Ç–∞–ª–æ–≥ ‚Äî –ø—Ä–æ—Å—Ç–æ —Å–∫–∞–∂–∏ üôÇ"

        for cat in PRODUCT_CATALOG:
            if low_clean == cat.lower():
                user_data["shopping_category"] = cat
                user_data.pop("awaiting_ad_choice")
                subs = ", ".join(PRODUCT_CATALOG[cat])
                return f"–û—Ç–ª–∏—á–Ω–æ! –ö–∞–∫–∏–µ –∏–º–µ–Ω–Ω–æ {cat.lower()} –∏–Ω—Ç–µ—Ä–µ—Å—É—é—Ç: {subs}?"

        # –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç ‚Äî —Å–Ω–∏–º–∞–µ–º —Ñ–ª–∞–≥, –∏–¥—ë–º –¥–∞–ª—å—à–µ
        user_data.pop("awaiting_ad_choice")

    # –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è + 1-—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è
    if "shopping_category" in user_data and "shopping_subcategory" not in user_data:
        cat = user_data["shopping_category"]
        for sub in PRODUCT_CATALOG[cat]:
            if low_clean in {sub.lower(), *sub.lower().split()}:
                user_data.update(
                    last_ad_category=cat,
                    last_ad_subcategory=sub,
                    expecting_more_ads=True,
                    ad_offer_done=True,
                )
                prod = random.choice(PRODUCT_CATALOG[cat][sub])
                user_data["shown_products"].add(prod["name"])
                user_data.pop("shopping_category")
                return (
                    f"–†–µ–∫–æ–º–µ–Ω–¥—É—é: *{prod['name']}*\n\n{prod['description']}\n\n"
                    f"–¶–µ–Ω–∞: {prod['price']} ‚ÇΩ\n–ü–æ–¥—Ä–æ–±–Ω–µ–µ: {prod['link']}"
                )

    # ¬´–ï—â—ë¬ª —Ç–æ–≤–∞—Ä—ã
    if user_data.get("expecting_more_ads") and low in {"–µ—â–µ", "–µ—â—ë", "–µ—â–µ —Ä–∞–∑", "–µ—â—ë —Ä–∞–∑"}:
        cat, sub = user_data["last_ad_category"], user_data["last_ad_subcategory"]
        rest = [p for p in PRODUCT_CATALOG[cat][sub] if p["name"] not in user_data["shown_products"]]
        if not rest:
            user_data["expecting_more_ads"] = False
            user_data["shown_products"].clear()
            return "–ü–æ–∂–∞–ª—É–π, —ç—Ç–æ –≤—Å–µ –ª—É—á—à–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã üòâ"
        prod = random.choice(rest)
        user_data["shown_products"].add(prod["name"])
        return (
            f"–ï—â—ë –≤–∞—Ä–∏–∞–Ω—Ç: *{prod['name']}*\n\n{prod['description']}\n\n"
            f"–¶–µ–Ω–∞: {prod['price']} ‚ÇΩ\n–ü–æ–¥—Ä–æ–±–Ω–µ–µ: {prod['link']}"
        )

    # teach-on-the-fly
    if waiting := user_data.get("awaiting_teach"):
        custom_ans[waiting] = text
        user_data.pop("awaiting_teach")
        return random.choice(["–°–ø–∞—Å–∏–±–æ, –∑–∞–ø–æ–º–Ω–∏–ª!", "–û—Ç–ª–∏—á–Ω–æ, –ø—Ä–∏–Ω—è–ª –∫ —Å–≤–µ–¥–µ–Ω–∏—é!"])

    # –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –æ—Ç–≤–µ—Ç—ã
    if text in custom_ans:
        return custom_ans[text]

    # –ª—é–±–∏–º–æ–µ X
    if "awaiting_pref_topic" in user_data:
        prefs[user_data.pop("awaiting_pref_topic")] = text
        return f"–°–ø–∞—Å–∏–±–æ! –Ø –∑–∞–ø–æ–º–Ω–∏–ª, —á—Ç–æ —Ç–µ–±–µ –Ω—Ä–∞–≤–∏—Ç—Å—è {text}."
    if (m := re.search(r"–ª—é–±–∏–º(?:–æ–µ|–∞—è|—ã–π|—ã–µ)\s+([\w\-–∞-—è—ë]+)", low_clean)):
        key = f"favorite_{m.group(1)}"
        if key in prefs:
            return f"–ú–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è {prefs[key]}."
        user_data["awaiting_pref_topic"] = key
        return f"–ê —á—Ç–æ —Ç–µ–±–µ –±–æ–ª—å—à–µ –≤—Å–µ–≥–æ –Ω—Ä–∞–≤–∏—Ç—Å—è –≤ –ø–ª–∞–Ω–µ {m.group(1)}?"

    # Encore
    if low in {"–µ—â–µ", "–µ—â—ë", "–µ—â–µ —Ä–∞–∑", "–µ—â—ë —Ä–∞–∑"}:
        if last_int in {"joke", "anecdote", "fun_fact", "fact"}:
            pool = [r for r in INTENTS[last_int]["responses"] if r != last_bot]
            return random.choice(pool) if pool else random.choice(INTENTS[last_int]["responses"])
        if last_int in {"music", "movie", "game", "series"}:
            return recommend(last_int, prefs.get(f"{last_int}_genre"))

    # –∫—Ä–µ—Å—Ç–∏–∫–∏-–Ω–æ–ª–∏–∫–∏
    if "–∫—Ä–µ—Å—Ç–∏–∫–∏" in low:
        user_data["tic_tac_toe"] = TicTacToe()
        return (
            "–ù–∞—á–∏–Ω–∞–µ–º ¬´–∫—Ä–µ—Å—Ç–∏–∫–∏-–Ω–æ–ª–∏–∫–∏¬ª!\n"
            f"{user_data['tic_tac_toe'].render()}\n–¢–≤–æ–π —Ö–æ–¥ (A1..C3):"
        )

    # –∂–∞–Ω—Ä –ø–æ—Å–ª–µ follow-up
    for cat in {"music", "movie", "game", "series"}:
        if last_int == cat and f"{cat}_genre" not in prefs:
            rec = recommend(cat, text.strip())
            prefs[f"{cat}_genre"] = text.strip()
            user_data["last_bot"] = rec
            return rec

    # sentiment
    lemma = lemmatize_text(
        " ".join(correct_spelling(w, DICTIONARY) for w in clean_text(text).split())
    )
    s = get_sentiment(lemma)
    tone = (
        "–ú–Ω–µ –æ—á–µ–Ω—å –∂–∞–ª—å, —á—Ç–æ —Ç–µ–±–µ –≥—Ä—É—Å—Ç–Ω–æ. "
        if s < -0.2
        else "–†–∞–¥ –∑–∞ —Ç–µ–±—è! "
        if s > 0.5
        else ""
    )

    # intent-predict
    intent = None
    for pred in (lambda x: clf.predict(x), lambda x: clf.predict_fuzzy(x)):
        try:
            cand = pred(lemma)
            if cand in INTENTS:
                intent = cand
                break
        except Exception:
            pass

    # media-intent
    if intent in {"music", "movie", "game", "series"}:
        user_data.update(last_intent=intent, asked_followup=True, awaiting_genre=intent)
        return INTENTS[intent]["follow_up"][0]

    # –æ–±—ã—á–Ω—ã–µ –∏–Ω—Ç–µ–Ω—Ç—ã
    if intent:
        opts = INTENTS[intent]["responses"]
        if last_bot in opts and len(opts) > 1:
            opts = [o for o in opts if o != last_bot]
        resp = random.choice(opts)
        user_data["last_bot"] = resp
        if not user_data["asked_followup"]:
            for f in INTENTS[intent].get("follow_up", []):
                if f not in user_data["asked_questions"]:
                    resp += " " + f
                    user_data["asked_questions"].add(f)
                    user_data["asked_followup"] = True
                    break
        user_data["last_intent"] = intent
        return tone + resp

    # retrieval-–æ—Ç–≤–µ—Ç
    if candidate := retriever.get_answer(lemma):
        user_data.update(last_bot=candidate, last_intent=None)
        return tone + candidate

    # Teach-fallback
    cid = f"c{re.sub(r'[^a-z0-9]', '', low_clean) or 'intent'}"
    new_i = {
        "examples": [text],
        "responses": ["–Ø –ø–æ–∫–∞ –Ω–µ –∑–Ω–∞—é, –∫–∞–∫ –Ω–∞ —ç—Ç–æ –æ—Ç–≤–µ—á–∞—Ç—å. –ü–æ–¥—Å–∫–∞–∂–∏—Ç–µ –ø—Ä–∏–º–µ—Ä –æ—Ç–≤–µ—Ç–∞?"],
    }
    extra = json.loads(CUSTOM_F.read_text("utf-8")) if CUSTOM_F.exists() else {}
    extra[cid] = new_i
    _save_custom_intents(extra)
    INTENTS[cid] = new_i
    user_data["awaiting_teach"] = text
    return "–Ø –ø–æ–∫–∞ –Ω–µ –∑–Ω–∞—é, –∫–∞–∫ –Ω–∞ —ç—Ç–æ –æ—Ç–≤–µ—á–∞—Ç—å. –ü–æ–¥—Å–∫–∞–∂–∏—Ç–µ –ø—Ä–∏–º–µ—Ä –æ—Ç–≤–µ—Ç–∞?"
